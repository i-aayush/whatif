{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = \"f\"\n",
    "trigger_word = \"akku\"\n",
    "gender_clothing = {\"m\": \"shirtless\", \"f\": \"wearing bikini\", \"default\": \"wearing long swim shorts\"}\n",
    "\n",
    "prompt1 =\"headshot of smiling model posing with a lot of cute puppies wearing casual clothes posing for dating app headshot. indoor blurry background. the lighting is warm, possibly from a setting sun, creating a soft glow around him, enhancing the casual and relaxed vibe of the image. the setting seems to be outdoors, likely in an urban environment, with the blurred background hinting at a street or park-like area. this image likely portrays a youthful, active, and approachable individual, possibly in a lifestyle or fashion-related context.\"\n",
    "prompt2 = \"A model wearing a cozy Christmas sweater, standing by the fireplace with stockings and holiday decorations.\"\n",
    "prompt3 = \"pov photo of model seated at restaurant table across from camera, in romantic upscale setting facing camera. medium rare steak is on the table sliced into several pieces, on a wooden board, which also has a small dish of what appears to be a side condiment or salsa with chopped vegetables.\"\n",
    "prompt4 = \"professional headshot of smiling model wearing professional clothes posing for headshot. blurry indoor office background. The overall vibe of the image is one of professionalism, likely intended for a formal or business-related setting, such as a corporate headshot or a professional profile picture.\"\n",
    "prompt5 = \"TedX speaker model holding microphone with lanyard around his neck\"\n",
    "prompt6 = \"beautiful influencer instagram model wearing elegant clothes sitting in private jet cabin, with leather interior, luxurious. champagne is on the table. outside is clouds because we are flying.\"\n",
    "prompt7 = \"model as fashion model in fashion shoot on catwalk.\"\n",
    "prompt8 = \"model as fashion model in street style shoot with diverse outfits.\"\n",
    "prompt9 = f\"the photo shows a fit {trigger_word}, {gender_clothing.get(gender, gender_clothing['default'])} happy model on the beach, playing volleyball, seemingly in preparation for a serve. model appears focused, with their gaze fixed on the ball. the background includes other beachgoers and beach equipment, but they are slightly blurred, emphasizing the model as the focal point. the model has a muscular build, with defined arms, chest, and abs. the volleyball holding is a mikasa brand, commonly used in beach volleyball. the setting suggests a warm, sunny day, perfect for beach activities.\"\n",
    "prompt10 = \"model wearing casual clothes in polaroid classic photograph posing for photo indoors\"\n",
    "prompt11 = \"casual profile headshot photo of model for Twitter. hasselblad photography.\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the photo shows a fit, wearing bikini happy model on the beach, playing volleyball, seemingly in preparation for a serve. model appears focused, with their gaze fixed on the ball. the background includes other beachgoers and beach equipment, but they are slightly blurred, emphasizing the model as the focal point. the model has a muscular build, with defined arms, chest, and abs. the volleyball holding is a mikasa brand, commonly used in beach volleyball. the setting suggests a warm, sunny day, perfect for beach activities.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import replicate\n",
    "\n",
    "# Ensure the path to your .env file is correct\n",
    "load_dotenv('/Users/aayushchaudhary/Desktop/vscode/whatif/backend/.env')  \n",
    "\n",
    "# Check if the environment variables are loaded correctly\n",
    "replicate_api_token = os.getenv('REPLICATE_API_TOKEN')\n",
    "aws_access_key_id = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prompt5' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 14\u001b[0m\n\u001b[1;32m      8\u001b[0m trigger_word \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maayu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m prompt1 \u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheadshot of smiling \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrigger_word\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m posing with a lot of cute puppies wearing casual clothes posing for dating app headshot. indoor blurry background. the lighting is warm, possibly from a setting sun, creating a soft glow around him, enhancing the casual and relaxed vibe of the image. the setting seems to be outdoors, likely in an urban environment, with the blurred background hinting at a street or park-like area. this image likely portrays a youthful, active, and approachable individual, possibly in a lifestyle or fashion-related context.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m output \u001b[38;5;241m=\u001b[39m replicate\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m     11\u001b[0m     model_id,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdev\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mprompt5\u001b[49m,\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgo_fast\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlora_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmegapixels\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maspect_ratio\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1:1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpng\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mguidance_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_quality\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_strength\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.96\u001b[39m,\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextra_lora_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_inference_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m41\u001b[39m\n\u001b[1;32m     26\u001b[0m     }\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prompt5' is not defined"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import replicate\n",
    "from dotenv import load_dotenv\n",
    "# load_dotenv('/backend/.env')  # Specify the path to your .env file\n",
    "replicate = replicate.Client(api_token=os.getenv('REPLICATE_API_TOKEN'))  # Initialize the client with the token\n",
    "i-aayush/aksh:d16dd47f430e689bfb43e1766e385744fd2ad13a38655c32dce07658ad1702f4\n",
    "\n",
    "model_id = \"i-aayush/my-flux:9010d504cf84e942e2fdd0d5f08b8fa45a63905407e66ab4b036df51a2460569\"\n",
    "trigger_word = \"aayu\"\n",
    "prompt1 =f\"headshot of smiling {trigger_word} posing with a lot of cute puppies wearing casual clothes posing for dating app headshot. indoor blurry background. the lighting is warm, possibly from a setting sun, creating a soft glow around him, enhancing the casual and relaxed vibe of the image. the setting seems to be outdoors, likely in an urban environment, with the blurred background hinting at a street or park-like area. this image likely portrays a youthful, active, and approachable individual, possibly in a lifestyle or fashion-related context.\"\n",
    "output = replicate.run(\n",
    "    model_id,\n",
    "    input={\n",
    "        \"model\": \"dev\",\n",
    "        \"prompt\": prompt5,\n",
    "        \"go_fast\": False,\n",
    "        \"lora_scale\": 1,\n",
    "        \"megapixels\": \"1\",\n",
    "        \"num_outputs\": 2,\n",
    "        \"aspect_ratio\": \"1:1\",\n",
    "        \"output_format\": \"png\",\n",
    "        \"guidance_scale\": 3,\n",
    "        \"output_quality\": 100,\n",
    "        \"prompt_strength\": 0.96,\n",
    "        \"extra_lora_scale\": 1,\n",
    "        \"num_inference_steps\": 41\n",
    "    }\n",
    ")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLICATE_USERNAME = \"i-aayush\" \n",
    "def create_replicate_model(client, model_name: str) -> str:\n",
    "    \"\"\"Creates a new model on Replicate if it doesn't exist.\"\"\"\n",
    "    try:\n",
    "        # Format the full model name\n",
    "        full_model_name = f\"{REPLICATE_USERNAME}/{model_name}\"\n",
    "        \n",
    "        # Create the model\n",
    "        model = client.models.create(\n",
    "            owner=REPLICATE_USERNAME,\n",
    "            name=model_name,\n",
    "            visibility=\"private\",\n",
    "            hardware=\"gpu-t4\",  # Using H100 GPU for faster training\n",
    "            description=f\"Custom trained model for {model_name}\"\n",
    "        )\n",
    "        return model\n",
    "    except replicate.exceptions.ReplicateError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url='https://replicate.com/i-aayush/screen_paper4' owner='i-aayush' name='screen_paper4' description='Custom trained model for screen_paper4' visibility='private' github_url=None paper_url=None license_url=None run_count=0 cover_image_url=None default_example=None latest_version=None\n"
     ]
    }
   ],
   "source": [
    "model_name = \"screen_paper4\"\n",
    "destination_model = create_replicate_model(replicate, model_name)\n",
    "print(destination_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training = replicate.trainings.create(\n",
    "            version=\"ostris/flux-dev-lora-trainer:e440909d3512c31646ee2e0c7d6f6f4923224863a6a10c494606e79fb5844497\",\n",
    "            input={\n",
    "                \"steps\": 2000,\n",
    "                \"lora_rank\": 16,\n",
    "                \"optimizer\": \"adamw8bit\",\n",
    "                \"batch_size\": 1,\n",
    "                \"resolution\": \"512,768,1024\",\n",
    "                \"autocaption\": True,\n",
    "                \"input_images\": \"https://whatif-genai.s3.us-east-1.amazonaws.com/training_data/6783da26d9f53afe5bf8b4a3.zip\",\n",
    "                \"trigger_word\": model_name,\n",
    "                \"learning_rate\": 0.0004,\n",
    "                \"wandb_project\": \"flux_train_replicate\",\n",
    "                \"wandb_save_interval\": 100,\n",
    "                \"caption_dropout_rate\": 0.05,\n",
    "                \"cache_latents_to_disk\": False,\n",
    "                \"wandb_sample_interval\": 100,\n",
    "                \"autocaption_suffix\": f\"In style of {model_name}\"\n",
    "            },\n",
    "            destination=destination_model\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output 1: https://replicate.delivery/xezq/LauRsYARbFYHJdk3nKggFjlNX1ZkOe6J3eZw2CYo006DIZEUA/out-0.png\n",
      "Output 2: https://replicate.delivery/xezq/ktbnxepXzATBIik21K4zPaz540gwhVErH2eReDsnZn0GQyIoA/out-1.png\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'output' contains the list of FileOutput objects\n",
    "for i, file_output in enumerate(output):\n",
    "    file_url = file_output.url  # This attribute typically contains the URL\n",
    "    print(f\"Output {i + 1}: {file_url}\")  # Print the URL of each output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('/backend/.env')  # Specify the path to your .env file\n",
    "aws_access_key_id = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "aws_secret_access_key = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    "s3_client = boto3.client('s3', region_name='us-east-1')  # Replace 'your-region' with your S3 region\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: [Errno 2] No such file or directory: './example.jpg'\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "s3_client = boto3.client('s3', region_name='us-east-1')  # Replace 'your-region' with your S3 region\n",
    "\n",
    "def upload_file_to_s3(file_path, bucket_name, object_name=None):\n",
    "    \"\"\"\n",
    "    Upload a file to an S3 bucket.\n",
    "    :param file_path: Local file path to upload\n",
    "    :param bucket_name: S3 bucket name\n",
    "    :param object_name: S3 object name (default: file name)\n",
    "    :return: Public URL of the uploaded file or None\n",
    "    \"\"\"\n",
    "    object_name = object_name or file_path.split('/')[-1]  # Default to file name\n",
    "    try:\n",
    "        s3_client.upload_file(\n",
    "            Filename=file_path,\n",
    "            Bucket=bucket_name,\n",
    "            Key=object_name,\n",
    "            ExtraArgs={'ContentType': 'image/jpeg'}\n",
    "        )\n",
    "        url = f\"https://{bucket_name}.s3.amazonaws.com/{object_name}\"\n",
    "        print(f\"File uploaded successfully: {url}\")\n",
    "        return url\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "upload_file_to_s3(\"./example.jpg\", \"whatif-genai\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aayushchaudhary/Desktop/instruction_images/clothes.png\n",
      "File uploaded successfully: https://whatif-genai.s3.amazonaws.com/clothes.png\n",
      "https://whatif-genai.s3.amazonaws.com/clothes.png\n",
      "/Users/aayushchaudhary/Desktop/instruction_images/blurry.png\n",
      "File uploaded successfully: https://whatif-genai.s3.amazonaws.com/blurry.png\n",
      "https://whatif-genai.s3.amazonaws.com/blurry.png\n",
      "/Users/aayushchaudhary/Desktop/instruction_images/group.png\n",
      "File uploaded successfully: https://whatif-genai.s3.amazonaws.com/group.png\n",
      "https://whatif-genai.s3.amazonaws.com/group.png\n",
      "/Users/aayushchaudhary/Desktop/instruction_images/poses.png\n",
      "File uploaded successfully: https://whatif-genai.s3.amazonaws.com/poses.png\n",
      "https://whatif-genai.s3.amazonaws.com/poses.png\n",
      "/Users/aayushchaudhary/Desktop/instruction_images/hats.png\n",
      "File uploaded successfully: https://whatif-genai.s3.amazonaws.com/hats.png\n",
      "https://whatif-genai.s3.amazonaws.com/hats.png\n",
      "/Users/aayushchaudhary/Desktop/instruction_images/clothes1.png\n",
      "File uploaded successfully: https://whatif-genai.s3.amazonaws.com/clothes1.png\n",
      "https://whatif-genai.s3.amazonaws.com/clothes1.png\n",
      "/Users/aayushchaudhary/Desktop/instruction_images/car_selfie.png\n",
      "File uploaded successfully: https://whatif-genai.s3.amazonaws.com/car_selfie.png\n",
      "https://whatif-genai.s3.amazonaws.com/car_selfie.png\n",
      "/Users/aayushchaudhary/Desktop/instruction_images/nude.png\n",
      "File uploaded successfully: https://whatif-genai.s3.amazonaws.com/nude.png\n",
      "https://whatif-genai.s3.amazonaws.com/nude.png\n",
      "['https://whatif-genai.s3.amazonaws.com/clothes.png', 'https://whatif-genai.s3.amazonaws.com/blurry.png', 'https://whatif-genai.s3.amazonaws.com/group.png', 'https://whatif-genai.s3.amazonaws.com/poses.png', 'https://whatif-genai.s3.amazonaws.com/hats.png', 'https://whatif-genai.s3.amazonaws.com/clothes1.png', 'https://whatif-genai.s3.amazonaws.com/car_selfie.png', 'https://whatif-genai.s3.amazonaws.com/nude.png']\n"
     ]
    }
   ],
   "source": [
    "list_files = []\n",
    "import os\n",
    "directory_path = '/Users/aayushchaudhary/Desktop/instruction_images'\n",
    "files = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
    "\n",
    "for file in files:\n",
    "    print(os.path.join(directory_path, file))\n",
    "    url = upload_file_to_s3(os.path.join(directory_path, file), \"whatif-genai\")\n",
    "    list_files.append(url)\n",
    "    print(url)\n",
    "print(list_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://whatif-genai.s3.amazonaws.com/clothes.png',\n",
       " 'https://whatif-genai.s3.amazonaws.com/blurry.png',\n",
       " 'https://whatif-genai.s3.amazonaws.com/group.png',\n",
       " 'https://whatif-genai.s3.amazonaws.com/poses.png',\n",
       " 'https://whatif-genai.s3.amazonaws.com/hats.png',\n",
       " 'https://whatif-genai.s3.amazonaws.com/clothes1.png',\n",
       " 'https://whatif-genai.s3.amazonaws.com/car_selfie.png',\n",
       " 'https://whatif-genai.s3.amazonaws.com/nude.png']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_word = \"aayu\"\n",
    "training = replicate.trainings.create(\n",
    "  # You need to create a model on Replicate that will be the destination for the trained version.\n",
    "  destination=f\"i-aayush/{trigger_word}\"\n",
    "  version=\"ostris/flux-dev-lora-trainer:e440909d3512c31646ee2e0c7d6f6f4923224863a6a10c494606e79fb5844497\",\n",
    "  input={\n",
    "    \"steps\": 2000,\n",
    "    \"lora_rank\": 16,\n",
    "    \"optimizer\": \"adamw8bit\",\n",
    "    \"batch_size\": 1,\n",
    "    \"resolution\": \"512,768,1024\",\n",
    "    \"autocaption\": True,\n",
    "    \"input_images\": \"https://\",\n",
    "    \"trigger_word\": f\"{trigger_word}\",\n",
    "    \"learning_rate\": 0.0004,\n",
    "    \"wandb_project\": \"flux_train_replicate\",\n",
    "    \"wandb_save_interval\": 100,\n",
    "    \"caption_dropout_rate\": 0.05,\n",
    "    \"cache_latents_to_disk\": False,\n",
    "    \"wandb_sample_interval\": 100\n",
    "  },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to MongoDB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.replicate.com/v1/trainings/eb1y070d3hrme0cmdwe972dfd8 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replicate Response:\n",
      "Status: succeeded\n",
      "Started at: 2025-01-16T12:34:56.933161Z\n",
      "Completed at: 2025-01-16T13:08:49.360599Z\n",
      "Output: {'version': 'i-aayush/aksh:d16dd47f430e689bfb43e1766e385744fd2ad13a38655c32dce07658ad1702f4', 'weights': 'https://replicate.delivery/xezq/T8feHl7Tp7sQSUmqN9Fwn1Q6z6v7wlj5E4aJvOE9DCAhbrFUA/trained_model.tar'}\n",
      "\n",
      "Training Duration: 33.87 minutes\n",
      "\n",
      "Updating user document...\n",
      "User update result - Modified count: 0\n",
      "\n",
      "Updating training run document...\n",
      "Training run update result - Modified count: 1\n",
      "\n",
      "Verifying updates...\n",
      "\n",
      "Updated training run: {'_id': ObjectId('6788fa45ab08ac11e1e11d59'), 'user_id': '6788ce89733ff8fad94d21b9', 'training_id': 'eb1y070d3hrme0cmdwe972dfd8', 'trigger_word': 'aksh', 'status': 'succeeded', 'created_at': datetime.datetime(2025, 1, 16, 12, 23, 33, 193000), 'version': 'i-aayush/aksh:d16dd47f430e689bfb43e1766e385744fd2ad13a38655c32dce07658ad1702f4', 'weights': 'https://replicate.delivery/xezq/T8feHl7Tp7sQSUmqN9Fwn1Q6z6v7wlj5E4aJvOE9DCAhbrFUA/trained_model.tar', 'completed_at': '2025-01-16T13:08:49.360599Z', 'error': None, 'started_at': '2025-01-16T12:34:56.933161Z', 'training_duration': 33.873790633333336, 'final_model_id': 'd16dd47f430e689bfb43e1766e385744fd2ad13a38655c32dce07658ad1702f4'}\n",
      "\n",
      "Updated user: None\n",
      "\n",
      "Closing MongoDB connection\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import replicate\n",
    "from motor.motor_asyncio import AsyncIOMotorClient\n",
    "from bson import ObjectId\n",
    "from datetime import datetime\n",
    "from app.config.config import settings\n",
    "\n",
    "async def test_poll_training():\n",
    "    try:\n",
    "        # Initialize MongoDB client with SSL settings\n",
    "        print(f\"Connecting to MongoDB: {settings.MONGODB_URI}\")\n",
    "        mongo_client = AsyncIOMotorClient(settings.MONGODB_URI, tlsAllowInvalidCertificates=True)\n",
    "        db = mongo_client[settings.DB_NAME]  # Use DB_NAME from settings\n",
    "        \n",
    "        # Test MongoDB connection\n",
    "        try:\n",
    "            await db.command('ping')\n",
    "            print(\"Successfully connected to MongoDB\")\n",
    "        except Exception as e:\n",
    "            print(f\"MongoDB connection test failed: {str(e)}\")\n",
    "            return\n",
    "            \n",
    "        # Initialize Replicate client\n",
    "        replicate_client = replicate.Client(api_token=os.getenv('REPLICATE_API_TOKEN'))\n",
    "        \n",
    "        # Your training ID and user ID\n",
    "        training_id = 'eb1y070d3hrme0cmdwe972dfd8'\n",
    "        user_id = ObjectId('6788ce89733ff8fad94d21b9')\n",
    "        \n",
    "        # Get training status from Replicate\n",
    "        status_response = replicate_client.trainings.get(training_id)\n",
    "        print(f\"\\nReplicate Response:\")\n",
    "        print(f\"Status: {status_response.status}\")\n",
    "        print(f\"Started at: {status_response.started_at}\")\n",
    "        print(f\"Completed at: {status_response.completed_at}\")\n",
    "        print(f\"Output: {status_response.output}\")\n",
    "        \n",
    "        # Calculate duration\n",
    "        training_duration = None\n",
    "        if status_response.completed_at and status_response.started_at:\n",
    "            start_time = datetime.fromisoformat(status_response.started_at.replace('Z', '+00:00'))\n",
    "            end_time = datetime.fromisoformat(status_response.completed_at.replace('Z', '+00:00'))\n",
    "            training_duration = (end_time - start_time).total_seconds() / 60\n",
    "            print(f\"\\nTraining Duration: {training_duration:.2f} minutes\")\n",
    "\n",
    "        # Prepare update data\n",
    "        update_data = {\n",
    "            \"status\": status_response.status,\n",
    "            \"started_at\": status_response.started_at,\n",
    "            \"completed_at\": status_response.completed_at,\n",
    "            \"training_duration\": training_duration,\n",
    "            \"error\": status_response.error\n",
    "        }\n",
    "        \n",
    "        if status_response.status == \"succeeded\":\n",
    "            model_output = {\n",
    "                \"version\": status_response.output.get(\"version\"),\n",
    "                \"weights\": status_response.output.get(\"weights\")\n",
    "            }\n",
    "            update_data.update({\n",
    "                \"version\": model_output[\"version\"],\n",
    "                \"weights\": model_output[\"weights\"],\n",
    "                \"final_model_id\": model_output[\"version\"].split(\":\")[-1] if model_output[\"version\"] else None\n",
    "            })\n",
    "            \n",
    "            # Update user document\n",
    "            print(\"\\nUpdating user document...\")\n",
    "            user_result = await db.users.update_one(\n",
    "                {\"_id\": user_id},\n",
    "                {\"$set\": {\n",
    "                    \"model_status\": \"completed\",\n",
    "                    \"current_training_id\": None,\n",
    "                    \"latest_model_version\": model_output[\"version\"],\n",
    "                    \"latest_model_weights\": model_output[\"weights\"]\n",
    "                }}\n",
    "            )\n",
    "            print(f\"User update result - Modified count: {user_result.modified_count}\")\n",
    "            \n",
    "        elif status_response.status in [\"failed\", \"canceled\"]:\n",
    "            error_message = status_response.error or \"Unknown error\"\n",
    "            print(f\"\\nError in training: {error_message}\")\n",
    "            \n",
    "            # Update user document for error\n",
    "            print(\"\\nUpdating user document with error...\")\n",
    "            user_result = await db.users.update_one(\n",
    "                {\"_id\": user_id},\n",
    "                {\"$set\": {\n",
    "                    \"model_status\": \"error\",\n",
    "                    \"current_training_id\": None,\n",
    "                    \"last_error\": error_message\n",
    "                }}\n",
    "            )\n",
    "            print(f\"User update result - Modified count: {user_result.modified_count}\")\n",
    "\n",
    "        # Update training run\n",
    "        print(\"\\nUpdating training run document...\")\n",
    "        training_result = await db.training_runs.update_one(\n",
    "            {\"training_id\": training_id},\n",
    "            {\"$set\": update_data}\n",
    "        )\n",
    "        print(f\"Training run update result - Modified count: {training_result.modified_count}\")\n",
    "        \n",
    "        # Verify updates\n",
    "        print(\"\\nVerifying updates...\")\n",
    "        training_run = await db.training_runs.find_one({\"training_id\": training_id})\n",
    "        user = await db.users.find_one({\"_id\": user_id})\n",
    "        \n",
    "        print(\"\\nUpdated training run:\", training_run)\n",
    "        print(\"\\nUpdated user:\", user)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        print(\"\\nClosing MongoDB connection\")\n",
    "        mongo_client.close()\n",
    "\n",
    "# Run the test\n",
    "await test_poll_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
