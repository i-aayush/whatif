{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = \"f\"\n",
    "trigger_word = \"akku\"\n",
    "gender_clothing = {\"m\": \"shirtless\", \"f\": \"wearing bikini\", \"default\": \"wearing long swim shorts\"}\n",
    "\n",
    "prompt1 =\"headshot of smiling model posing with a lot of cute puppies wearing casual clothes posing for dating app headshot. indoor blurry background. the lighting is warm, possibly from a setting sun, creating a soft glow around him, enhancing the casual and relaxed vibe of the image. the setting seems to be outdoors, likely in an urban environment, with the blurred background hinting at a street or park-like area. this image likely portrays a youthful, active, and approachable individual, possibly in a lifestyle or fashion-related context.\"\n",
    "prompt2 = \"A model wearing a cozy Christmas sweater, standing by the fireplace with stockings and holiday decorations.\"\n",
    "prompt3 = \"pov photo of model seated at restaurant table across from camera, in romantic upscale setting facing camera. medium rare steak is on the table sliced into several pieces, on a wooden board, which also has a small dish of what appears to be a side condiment or salsa with chopped vegetables.\"\n",
    "prompt4 = \"professional headshot of smiling model wearing professional clothes posing for headshot. blurry indoor office background. The overall vibe of the image is one of professionalism, likely intended for a formal or business-related setting, such as a corporate headshot or a professional profile picture.\"\n",
    "prompt5 = \"TedX speaker model holding microphone with lanyard around his neck\"\n",
    "prompt6 = \"beautiful influencer instagram model wearing elegant clothes sitting in private jet cabin, with leather interior, luxurious. champagne is on the table. outside is clouds because we are flying.\"\n",
    "prompt7 = \"model as fashion model in fashion shoot on catwalk.\"\n",
    "prompt8 = \"model as fashion model in street style shoot with diverse outfits.\"\n",
    "prompt9 = f\"the photo shows a fit {trigger_word}, {gender_clothing.get(gender, gender_clothing['default'])} happy model on the beach, playing volleyball, seemingly in preparation for a serve. model appears focused, with their gaze fixed on the ball. the background includes other beachgoers and beach equipment, but they are slightly blurred, emphasizing the model as the focal point. the model has a muscular build, with defined arms, chest, and abs. the volleyball holding is a mikasa brand, commonly used in beach volleyball. the setting suggests a warm, sunny day, perfect for beach activities.\"\n",
    "prompt10 = \"model wearing casual clothes in polaroid classic photograph posing for photo indoors\"\n",
    "prompt11 = \"casual profile headshot photo of model for Twitter. hasselblad photography.\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the photo shows a fit, wearing bikini happy model on the beach, playing volleyball, seemingly in preparation for a serve. model appears focused, with their gaze fixed on the ball. the background includes other beachgoers and beach equipment, but they are slightly blurred, emphasizing the model as the focal point. the model has a muscular build, with defined arms, chest, and abs. the volleyball holding is a mikasa brand, commonly used in beach volleyball. the setting suggests a warm, sunny day, perfect for beach activities.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replicate API Token: r8_IrPNNhZt7r2girOkcyN2GY1gLvURBew1fvAGD\n",
      "AWS Access Key ID: AKIA2UC3B4NJ45FD2UMR\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Ensure the path to your .env file is correct\n",
    "load_dotenv('/Users/aayushchaudhary/Desktop/vscode/whatif/backend/.env')  \n",
    "\n",
    "# Check if the environment variables are loaded correctly\n",
    "replicate_api_token = os.getenv('REPLICATE_API_TOKEN')\n",
    "aws_access_key_id = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "\n",
    "# Print the values to verify they are not None\n",
    "print(f\"Replicate API Token: {replicate_api_token}\")\n",
    "print(f\"AWS Access Key ID: {aws_access_key_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<replicate.helpers.FileOutput object at 0x10729d9d0>, <replicate.helpers.FileOutput object at 0x1072194d0>]\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import replicate\n",
    "from dotenv import load_dotenv\n",
    "# load_dotenv('/backend/.env')  # Specify the path to your .env file\n",
    "replicate = replicate.Client(api_token=os.getenv('REPLICATE_API_TOKEN'))  # Initialize the client with the token\n",
    "\n",
    "model_id = \"i-aayush/my-flux:9010d504cf84e942e2fdd0d5f08b8fa45a63905407e66ab4b036df51a2460569\"\n",
    "trigger_word = \"aayu\"\n",
    "prompt1 =f\"headshot of smiling {trigger_word} posing with a lot of cute puppies wearing casual clothes posing for dating app headshot. indoor blurry background. the lighting is warm, possibly from a setting sun, creating a soft glow around him, enhancing the casual and relaxed vibe of the image. the setting seems to be outdoors, likely in an urban environment, with the blurred background hinting at a street or park-like area. this image likely portrays a youthful, active, and approachable individual, possibly in a lifestyle or fashion-related context.\"\n",
    "output = replicate.run(\n",
    "    model_id,\n",
    "    input={\n",
    "        \"model\": \"dev\",\n",
    "        \"prompt\": prompt5,\n",
    "        \"go_fast\": False,\n",
    "        \"lora_scale\": 1,\n",
    "        \"megapixels\": \"1\",\n",
    "        \"num_outputs\": 2,\n",
    "        \"aspect_ratio\": \"1:1\",\n",
    "        \"output_format\": \"png\",\n",
    "        \"guidance_scale\": 3,\n",
    "        \"output_quality\": 100,\n",
    "        \"prompt_strength\": 0.96,\n",
    "        \"extra_lora_scale\": 1,\n",
    "        \"num_inference_steps\": 41\n",
    "    }\n",
    ")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLICATE_USERNAME = \"i-aayush\" \n",
    "def create_replicate_model(client, model_name: str) -> str:\n",
    "    \"\"\"Creates a new model on Replicate if it doesn't exist.\"\"\"\n",
    "    try:\n",
    "        # Format the full model name\n",
    "        full_model_name = f\"{REPLICATE_USERNAME}/{model_name}\"\n",
    "        \n",
    "        # Create the model\n",
    "        model = client.models.create(\n",
    "            owner=REPLICATE_USERNAME,\n",
    "            name=model_name,\n",
    "            visibility=\"private\",\n",
    "            hardware=\"gpu-t4\",  # Using H100 GPU for faster training\n",
    "            description=f\"Custom trained model for {model_name}\"\n",
    "        )\n",
    "        return full_model_name\n",
    "    except replicate.exceptions.ReplicateError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Client' object has no attribute 'exceptions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mReplicateError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 9\u001b[0m, in \u001b[0;36mcreate_replicate_model\u001b[0;34m(client, model_name)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Create the model\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mowner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mREPLICATE_USERNAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisibility\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprivate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhardware\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpu-h100\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Using H100 GPU for faster training\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCustom trained model for \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     15\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m full_model_name\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/replicate/model.py:360\u001b[0m, in \u001b[0;36mModels.create\u001b[0;34m(self, owner, name, **params)\u001b[0m\n\u001b[1;32m    359\u001b[0m body \u001b[38;5;241m=\u001b[39m _create_model_body(owner, name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 360\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/v1/models\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _json_to_model(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client, resp\u001b[38;5;241m.\u001b[39mjson())\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/replicate/client.py:89\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, method, path, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mrequest(method, path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 89\u001b[0m \u001b[43m_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/replicate/client.py:393\u001b[0m, in \u001b[0;36m_raise_for_status\u001b[0;34m(resp)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m400\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m resp\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m600\u001b[39m:\n\u001b[0;32m--> 393\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReplicateError\u001b[38;5;241m.\u001b[39mfrom_response(resp)\n",
      "\u001b[0;31mReplicateError\u001b[0m: ReplicateError Details:\ntitle: Validation failed\nstatus: 400\ndetail: The following errors occurred:\n- hardware: gpu-h100 is not a valid hardware SKU. Your options are: cpu, gpu-a100-large, gpu-l40s, gpu-t4.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscreen_paper\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m destination_model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_replicate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m training \u001b[38;5;241m=\u001b[39m replicate\u001b[38;5;241m.\u001b[39mtrainings\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      5\u001b[0m             version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mostris/flux-dev-lora-trainer:e440909d3512c31646ee2e0c7d6f6f4923224863a6a10c494606e79fb5844497\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m             \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m             destination\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mselect/create\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     24\u001b[0m         )\n",
      "Cell \u001b[0;32mIn[30], line 17\u001b[0m, in \u001b[0;36mcreate_replicate_model\u001b[0;34m(client, model_name)\u001b[0m\n\u001b[1;32m      9\u001b[0m     model \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     10\u001b[0m         owner\u001b[38;5;241m=\u001b[39mREPLICATE_USERNAME,\n\u001b[1;32m     11\u001b[0m         name\u001b[38;5;241m=\u001b[39mmodel_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m         description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCustom trained model for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m     )\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m full_model_name\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[43mreplicate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexceptions\u001b[49m\u001b[38;5;241m.\u001b[39mReplicateError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(e)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Client' object has no attribute 'exceptions'"
     ]
    }
   ],
   "source": [
    "model_name = \"screen_paper\"\n",
    "destination_model = create_replicate_model(replicate, model_name)\n",
    "\n",
    "training = replicate.trainings.create(\n",
    "            version=\"ostris/flux-dev-lora-trainer:e440909d3512c31646ee2e0c7d6f6f4923224863a6a10c494606e79fb5844497\",\n",
    "            input={\n",
    "                \"steps\": 2000,\n",
    "                \"lora_rank\": 16,\n",
    "                \"optimizer\": \"adamw8bit\",\n",
    "                \"batch_size\": 1,\n",
    "                \"resolution\": \"512,768,1024\",\n",
    "                \"autocaption\": True,\n",
    "                \"input_images\": \"https://us-east-1.console.aws.amazon.com/s3/object/whatif-genai?region=us-east-1&bucketType=general&prefix=training_data/6783da26d9f53afe5bf8b4a3.zip\",\n",
    "                \"trigger_word\": model_name,\n",
    "                \"learning_rate\": 0.0004,\n",
    "                \"wandb_project\": \"flux_train_replicate\",\n",
    "                \"wandb_save_interval\": 100,\n",
    "                \"caption_dropout_rate\": 0.05,\n",
    "                \"cache_latents_to_disk\": False,\n",
    "                \"wandb_sample_interval\": 100,\n",
    "                \"autocaption_suffix\": f\"In style of {model_name}\"\n",
    "            },\n",
    "            destination=f\"select/create\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output 1: https://replicate.delivery/xezq/LauRsYARbFYHJdk3nKggFjlNX1ZkOe6J3eZw2CYo006DIZEUA/out-0.png\n",
      "Output 2: https://replicate.delivery/xezq/ktbnxepXzATBIik21K4zPaz540gwhVErH2eReDsnZn0GQyIoA/out-1.png\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'output' contains the list of FileOutput objects\n",
    "for i, file_output in enumerate(output):\n",
    "    file_url = file_output.url  # This attribute typically contains the URL\n",
    "    print(f\"Output {i + 1}: {file_url}\")  # Print the URL of each output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('/backend/.env')  # Specify the path to your .env file\n",
    "aws_access_key_id = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "aws_secret_access_key = os.getenv('AWS_SECRET_ACCESS_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: [Errno 2] No such file or directory: './example.jpg'\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "s3_client = boto3.client('s3', region_name='us-east-1')  # Replace 'your-region' with your S3 region\n",
    "\n",
    "def upload_file_to_s3(file_path, bucket_name, object_name=None):\n",
    "    \"\"\"\n",
    "    Upload a file to an S3 bucket.\n",
    "    :param file_path: Local file path to upload\n",
    "    :param bucket_name: S3 bucket name\n",
    "    :param object_name: S3 object name (default: file name)\n",
    "    :return: Public URL of the uploaded file or None\n",
    "    \"\"\"\n",
    "    object_name = object_name or file_path.split('/')[-1]  # Default to file name\n",
    "    try:\n",
    "        s3_client.upload_file(\n",
    "            Filename=file_path,\n",
    "            Bucket=bucket_name,\n",
    "            Key=object_name,\n",
    "            ExtraArgs={'ContentType': 'image/jpeg'}\n",
    "        )\n",
    "        url = f\"https://{bucket_name}.s3.amazonaws.com/{object_name}\"\n",
    "        print(f\"File uploaded successfully: {url}\")\n",
    "        return url\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "upload_file_to_s3(\"./example.jpg\", \"whatif-genai\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aayushchaudhary/Desktop/instruction_images/clothes.png\n",
      "File uploaded successfully: https://whatif-genai.s3.amazonaws.com/clothes.png\n",
      "https://whatif-genai.s3.amazonaws.com/clothes.png\n",
      "/Users/aayushchaudhary/Desktop/instruction_images/blurry.png\n",
      "File uploaded successfully: https://whatif-genai.s3.amazonaws.com/blurry.png\n",
      "https://whatif-genai.s3.amazonaws.com/blurry.png\n",
      "/Users/aayushchaudhary/Desktop/instruction_images/group.png\n",
      "File uploaded successfully: https://whatif-genai.s3.amazonaws.com/group.png\n",
      "https://whatif-genai.s3.amazonaws.com/group.png\n",
      "/Users/aayushchaudhary/Desktop/instruction_images/poses.png\n",
      "File uploaded successfully: https://whatif-genai.s3.amazonaws.com/poses.png\n",
      "https://whatif-genai.s3.amazonaws.com/poses.png\n",
      "/Users/aayushchaudhary/Desktop/instruction_images/hats.png\n",
      "File uploaded successfully: https://whatif-genai.s3.amazonaws.com/hats.png\n",
      "https://whatif-genai.s3.amazonaws.com/hats.png\n",
      "/Users/aayushchaudhary/Desktop/instruction_images/clothes1.png\n",
      "File uploaded successfully: https://whatif-genai.s3.amazonaws.com/clothes1.png\n",
      "https://whatif-genai.s3.amazonaws.com/clothes1.png\n",
      "/Users/aayushchaudhary/Desktop/instruction_images/car_selfie.png\n",
      "File uploaded successfully: https://whatif-genai.s3.amazonaws.com/car_selfie.png\n",
      "https://whatif-genai.s3.amazonaws.com/car_selfie.png\n",
      "/Users/aayushchaudhary/Desktop/instruction_images/nude.png\n",
      "File uploaded successfully: https://whatif-genai.s3.amazonaws.com/nude.png\n",
      "https://whatif-genai.s3.amazonaws.com/nude.png\n",
      "['https://whatif-genai.s3.amazonaws.com/clothes.png', 'https://whatif-genai.s3.amazonaws.com/blurry.png', 'https://whatif-genai.s3.amazonaws.com/group.png', 'https://whatif-genai.s3.amazonaws.com/poses.png', 'https://whatif-genai.s3.amazonaws.com/hats.png', 'https://whatif-genai.s3.amazonaws.com/clothes1.png', 'https://whatif-genai.s3.amazonaws.com/car_selfie.png', 'https://whatif-genai.s3.amazonaws.com/nude.png']\n"
     ]
    }
   ],
   "source": [
    "list_files = []\n",
    "import os\n",
    "directory_path = '/Users/aayushchaudhary/Desktop/instruction_images'\n",
    "files = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
    "\n",
    "for file in files:\n",
    "    print(os.path.join(directory_path, file))\n",
    "    url = upload_file_to_s3(os.path.join(directory_path, file), \"whatif-genai\")\n",
    "    list_files.append(url)\n",
    "    print(url)\n",
    "print(list_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://whatif-genai.s3.amazonaws.com/clothes.png',\n",
       " 'https://whatif-genai.s3.amazonaws.com/blurry.png',\n",
       " 'https://whatif-genai.s3.amazonaws.com/group.png',\n",
       " 'https://whatif-genai.s3.amazonaws.com/poses.png',\n",
       " 'https://whatif-genai.s3.amazonaws.com/hats.png',\n",
       " 'https://whatif-genai.s3.amazonaws.com/clothes1.png',\n",
       " 'https://whatif-genai.s3.amazonaws.com/car_selfie.png',\n",
       " 'https://whatif-genai.s3.amazonaws.com/nude.png']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_word = \"aayu\"\n",
    "training = replicate.trainings.create(\n",
    "  # You need to create a model on Replicate that will be the destination for the trained version.\n",
    "  destination=f\"i-aayush/{trigger_word}\"\n",
    "  version=\"ostris/flux-dev-lora-trainer:e440909d3512c31646ee2e0c7d6f6f4923224863a6a10c494606e79fb5844497\",\n",
    "  input={\n",
    "    \"steps\": 2000,\n",
    "    \"lora_rank\": 16,\n",
    "    \"optimizer\": \"adamw8bit\",\n",
    "    \"batch_size\": 1,\n",
    "    \"resolution\": \"512,768,1024\",\n",
    "    \"autocaption\": True,\n",
    "    \"input_images\": \"https://\",\n",
    "    \"trigger_word\": f\"{trigger_word}\",\n",
    "    \"learning_rate\": 0.0004,\n",
    "    \"wandb_project\": \"flux_train_replicate\",\n",
    "    \"wandb_save_interval\": 100,\n",
    "    \"caption_dropout_rate\": 0.05,\n",
    "    \"cache_latents_to_disk\": False,\n",
    "    \"wandb_sample_interval\": 100\n",
    "  },\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
